{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26606849",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters in this cell can be overriden using papermill\n",
    "\n",
    "# path to directory contaning output from the extract_test_outputs method in analyze.py\n",
    "ANALYSIS_DIR=\".\"\n",
    "\n",
    "# If no cached 'meshes.gz' file exists when loading data, setting\n",
    "# DERIVE_MESHES to True causes the mesh state to be derived from\n",
    "# trace events. This will add several minutes to the load time,\n",
    "# but the results will be cached to disk.\n",
    "DERIVE_MESHES=False\n",
    "\n",
    "# When DERIVE_MESHES is true, you can change the sample frequency\n",
    "# by setting MESH_SAMPLE_FREQ. This controls the size of the time window\n",
    "# for each mesh \"snapshot\".\n",
    "MESH_SAMPLE_FREQ='5s'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "115b4bb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosave disabled\n",
      "loading test data from .\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "import argparse\n",
    "import os\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import toml\n",
    "import ipywidgets as widgets\n",
    "from pprint import pprint\n",
    "import pathlib\n",
    "import seaborn as sns\n",
    "from durations import Duration\n",
    "\n",
    "import notebook_helper\n",
    "from notebook_helper import no_scores_message, load_pandas, archive_figures, p25, p50, p75, p95, p99\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tikuna.models import LSTM\n",
    "from tikuna.common.preprocess import FeatureExtractor\n",
    "from tikuna.common.dataloader import load_sessions, log_dataset, log_dataset_scores\n",
    "from tikuna.common.utils import seed_everything, dump_final_results, dump_params\n",
    "\n",
    "# render charts in a larger, zoomable style\n",
    "%matplotlib notebook\n",
    "\n",
    "# turn off autosaving for the notebook\n",
    "%autosave 0\n",
    "\n",
    "# load data\n",
    "print('loading test data from ' + ANALYSIS_DIR)\n",
    "\n",
    "tables = load_pandas(ANALYSIS_DIR, derive_meshes_if_missing=DERIVE_MESHES, mesh_sample_freq=MESH_SAMPLE_FREQ)\n",
    "scores = tables['scores']\n",
    "scores = scores.dropna()\n",
    "scores = scores.sort_values(['timestamp', 'observer', 'peer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ed42703",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-18 21:16:09,662 P3171391 INFO {\n",
      "    \"model_name\": \"LSTM\",\n",
      "    \"use_attention\": false,\n",
      "    \"hidden_size\": 128,\n",
      "    \"num_layers\": 2,\n",
      "    \"num_directions\": 2,\n",
      "    \"embedding_dim\": 7,\n",
      "    \"dataset\": \"testground score components\",\n",
      "    \"window_size\": 10,\n",
      "    \"stride\": 1,\n",
      "    \"feature_type\": \"sequentials\",\n",
      "    \"label_type\": \"next_log\",\n",
      "    \"use_tfidf\": false,\n",
      "    \"max_token_len\": 50,\n",
      "    \"min_token_count\": 1,\n",
      "    \"epoches\": 10,\n",
      "    \"batch_size\": 100,\n",
      "    \"learning_rate\": 0.01,\n",
      "    \"topk\": 7,\n",
      "    \"patience\": 10,\n",
      "    \"random_seed\": 42,\n",
      "    \"gpu\": 0,\n",
      "    \"hash_id\": \"3e773264\"\n",
      "}\n",
      "2022-11-18 21:16:28,130 P3171391 INFO Start training on 90 batches with cpu.\n",
      "2022-11-18 21:16:34,973 P3171391 INFO Epoch 1/10, training loss: 0.02236 [6.84s]\n",
      "2022-11-18 21:16:34,974 P3171391 INFO Evaluating test data.\n",
      "2022-11-18 21:18:01,803 P3171391 INFO Saving model to ./experiment_records/3e773264/model.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TP] 0\t[FP] 0\t[MISSED] 0\n",
      "[TN] 18554\t[FN] 0\n",
      "[ACC] 18554 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-18 21:18:09,484 P3171391 INFO Epoch 2/10, training loss: 0.02185 [7.68s]\n",
      "2022-11-18 21:18:09,485 P3171391 INFO Evaluating test data.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [3], line 57\u001b[0m\n\u001b[1;32m     51\u001b[0m dataloader_test \u001b[38;5;241m=\u001b[39m DataLoader(\n\u001b[1;32m     52\u001b[0m     dataset_test, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, pin_memory\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     53\u001b[0m )\n\u001b[1;32m     55\u001b[0m model \u001b[38;5;241m=\u001b[39m LSTM(meta_data\u001b[38;5;241m=\u001b[39mmeta_data, model_save_path\u001b[38;5;241m=\u001b[39mmodel_save_path, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[0;32m---> 57\u001b[0m eval_results \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataloader_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataloader_test\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepoches\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mepoches\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlearning_rate\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     64\u001b[0m result_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m-\u001b[39m\u001b[38;5;132;01m{:.4f}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(k, v) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m eval_results\u001b[38;5;241m.\u001b[39mitems()])\n\u001b[1;32m     66\u001b[0m key_info \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataset\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_anomaly_ratio\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_attention\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     72\u001b[0m ]\n",
      "File \u001b[0;32m~/app/data/../tikuna/models/base_model.py:377\u001b[0m, in \u001b[0;36mForcastBasedModel.fit\u001b[0;34m(self, train_loader, test_loader, epoches, learning_rate)\u001b[0m\n\u001b[1;32m    374\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime_tracker[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m epoch_time_elapsed\n\u001b[1;32m    376\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m test_loader \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m (epoch \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m--> 377\u001b[0m     eval_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    378\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m eval_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mf1\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m>\u001b[39m best_f1:\n\u001b[1;32m    379\u001b[0m         best_f1 \u001b[38;5;241m=\u001b[39m eval_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mf1\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/app/data/../tikuna/models/base_model.py:88\u001b[0m, in \u001b[0;36mForcastBasedModel.evaluate\u001b[0;34m(self, test_loader, dtype)\u001b[0m\n\u001b[1;32m     85\u001b[0m logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEvaluating \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m data.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(dtype))\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabel_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnext_log\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 88\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__evaluate_next_log_scores\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabel_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124manomaly\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     90\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__evaluate_anomaly(test_loader, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "File \u001b[0;32m~/app/data/../tikuna/models/base_model.py:278\u001b[0m, in \u001b[0;36mForcastBasedModel.__evaluate_next_log_scores\u001b[0;34m(self, test_loader, dtype)\u001b[0m\n\u001b[1;32m    276\u001b[0m infer_start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_input \u001b[38;5;129;01min\u001b[39;00m test_loader:\n\u001b[0;32m--> 278\u001b[0m     return_dict \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__input2device\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_input\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    279\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m return_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_pred\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    280\u001b[0m     loss \u001b[38;5;241m=\u001b[39m return_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/app/data/../tikuna/models/lstm.py:109\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[0;34m(self, input_dict)\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_tfidf:\n\u001b[1;32m    107\u001b[0m         x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39msum(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m)  \u001b[38;5;66;03m# add tf-idf\u001b[39;00m\n\u001b[0;32m--> 109\u001b[0m outputs, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_attention:\n\u001b[1;32m    112\u001b[0m     representation \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattn(outputs)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:532\u001b[0m, in \u001b[0;36mModule.__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slow_forward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 532\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    533\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mvalues():\n\u001b[1;32m    534\u001b[0m     hook_result \u001b[38;5;241m=\u001b[39m hook(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, result)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/rnn.py:558\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    556\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_forward_args(\u001b[38;5;28minput\u001b[39m, hx, batch_sizes)\n\u001b[1;32m    557\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 558\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    559\u001b[0m \u001b[43m                      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbidirectional\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_first\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    560\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    561\u001b[0m     result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mlstm(\u001b[38;5;28minput\u001b[39m, batch_sizes, hx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias,\n\u001b[1;32m    562\u001b[0m                       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "##### Model params\n",
    "parser.add_argument(\"--model_name\", default=\"LSTM\", type=str)\n",
    "parser.add_argument(\"--use_attention\", action=\"store_true\")\n",
    "parser.add_argument(\"--hidden_size\", default=128, type=int)\n",
    "parser.add_argument(\"--num_layers\", default=2, type=int)\n",
    "parser.add_argument(\"--num_directions\", default=2, type=int)\n",
    "parser.add_argument(\"--embedding_dim\", default=7, type=int)\n",
    "\n",
    "##### Dataset params\n",
    "parser.add_argument(\"--dataset\", default=\"testground score components\", type=str)\n",
    "parser.add_argument(\"--window_size\", default=10, type=int)\n",
    "parser.add_argument(\"--stride\", default=1, type=int)\n",
    "\n",
    "##### Input params\n",
    "parser.add_argument(\"--feature_type\", default=\"sequentials\", type=str, choices=[\"sequentials\", \"semantics\"])\n",
    "parser.add_argument(\"--label_type\", default=\"next_log\", type=str)\n",
    "parser.add_argument(\"--use_tfidf\", action=\"store_true\")\n",
    "parser.add_argument(\"--max_token_len\", default=50, type=int)\n",
    "parser.add_argument(\"--min_token_count\", default=1, type=int)\n",
    "\n",
    "##### Training params\n",
    "parser.add_argument(\"--epoches\", default=10, type=int)\n",
    "parser.add_argument(\"--batch_size\", default=100, type=int)\n",
    "parser.add_argument(\"--learning_rate\", default=0.01, type=float)\n",
    "parser.add_argument(\"--topk\", default=7, type=int)\n",
    "parser.add_argument(\"--patience\", default=10, type=int)\n",
    "\n",
    "##### Others\n",
    "parser.add_argument(\"--random_seed\", default=42, type=int)\n",
    "parser.add_argument(\"--gpu\", default=0, type=int)\n",
    "\n",
    "args, unknown = parser.parse_known_args()\n",
    "params = vars(args)\n",
    "\n",
    "model_save_path = dump_params(params)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    seed_everything(params[\"random_seed\"])\n",
    "    meta_data = {'num_labels':7, 'vocab_size': 14}\n",
    "    \n",
    "    dataset_train = log_dataset_scores(scores)\n",
    "    \n",
    "    dataloader_train = DataLoader(\n",
    "        dataset_train, batch_size=params[\"batch_size\"], shuffle=True, pin_memory=True\n",
    "    )\n",
    "\n",
    "    dataset_test = log_dataset_scores(scores[10000:20000])\n",
    "    dataloader_test = DataLoader(\n",
    "        dataset_test, batch_size=10, shuffle=False, pin_memory=True\n",
    "    )\n",
    "\n",
    "    model = LSTM(meta_data=meta_data, model_save_path=model_save_path, **params)\n",
    "\n",
    "    eval_results = model.fit(\n",
    "        dataloader_train,\n",
    "        test_loader=dataloader_test,\n",
    "        epoches=params[\"epoches\"],\n",
    "        learning_rate=params[\"learning_rate\"],\n",
    "    )\n",
    "\n",
    "    result_str = \"\\t\".join([\"{}-{:.4f}\".format(k, v) for k, v in eval_results.items()])\n",
    "\n",
    "    key_info = [\n",
    "        \"dataset\",\n",
    "        \"train_anomaly_ratio\",\n",
    "        \"feature_type\",\n",
    "        \"label_type\",\n",
    "        \"use_attention\",\n",
    "    ]\n",
    "\n",
    "    args_str = \"\\t\".join(\n",
    "        [\"{}:{}\".format(k, v) for k, v in params.items() if k in key_info]\n",
    "    )\n",
    "\n",
    "    dump_final_results(params, eval_results, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15709b40",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
